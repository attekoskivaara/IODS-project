# Logistic regression

### 1) R markdown is created
```{r}
date()
```

### 2) Load dataset and examine column names and dimensions
```{r}
library(tidyverse)

stu <- read_csv("alc.csv")

dim(stu)

colnames(stu)
```

The data set is a joined from questionnaires targeted for two Portuguese schools. Its attributes include student grades, demographic, social and school related features) 


### 3) Variable selection
```{r}
glimpse(stu)

stu2 <- select(stu, absences, G3, freetime, goout, high_use)
  
```
I assume that higher levels of absences, freetime and going out are linked with higher alcohol consumption. Maybe it will lead to lower grades (G3) as well.


### 4) Variable exploration and analysis
```{r}

# initialize a plot of high_use and G3
g1 <- ggplot(stu2, aes(x = high_use, y = G3))

# define the plot as a boxplot and draw it
g1 + geom_boxplot() + ylab("grade")

# initialize a plot of absences and high_use
g2 <- ggplot(stu2, aes(x = high_use, y = absences))

# define the plot as a boxplot and draw it
g2 + geom_boxplot() + ylab("absences")

g3 <- ggplot(stu2, aes(x = high_use, y = freetime))
g3 + geom_boxplot() + ylab("freetime")

g4 <- ggplot(stu2, aes(x= high_use, y = goout))
g4 + geom_boxplot() + ylab("Go out")

```
I would say that my hypothses were right except for freetime which does not seem to have a large effect. 

### 5) Logistic regression
```{r}
library(dplyr)

# create log. regr. model with glm()
m <- glm(high_use ~ absences + G3 + freetime + goout, data = stu2, family = "binomial")

# print out a summary of the model
summary(m)
```
**Summary:** According to the fitted model, variables absences and going out have a statistically significant relationship with high use of alcohol. Furthermore, results indicate that the higher value in absences or goout, the more likely it is for a student to be a high user. 

Other two variables (freetime and grade) do not have a statistically significant relationship with high_use.

```{r}
# model coefficients
coef(m)

# compute odds ratios
OR <- coef(m) %>% exp

# compute confidence intervals
CI <- confint(m) %>% exp

# print out the odds ratios with their confidence intervals
cbind(OR, CI)

```


**Coefficients as odds ratios:** All of the variables except grade have a similar relationship with high use --> the higher absences, freetime or going out values are the higher chance of high use. **For example with "goout"** variable, if we hold other variables constant, with one-unit increase in goout, we see 94% chance of high use of alcohol.  

Shortly, my hypothesis in the begin was largely accurate. However, I was not that precise with them (I did not consider if some variable will prove statistically significant)


### 6) Cross tabulation with statistically significant variables

```{r}
library(dplyr)
# Create model with variables with significant relationship with high_use
stu3 <- select(stu2, high_use, absences, goout)
m2 <- glm(high_use ~ absences + goout, data = stu3, family = "binomial")

# predict probability of high use
probabilities <- predict(m2, type="response")

stu3 <- stu3 %>% 
  mutate(probability = probabilities) %>%
  mutate(prediction = probability > .5)

# cross tabulation
table(high_use = stu3$high_use, prediction = stu3$prediction)

# initialize a plot of 'high_use' versus 'probability' in 'alc'
g <- ggplot(stu3, aes(x = high_use, y = probability))


# define the geom as points and draw the plot
g + geom_point(aes(col=prediction))


table(high_use = stu3$high_use, prediction = stu3$prediction) %>% prop.table %>% addmargins

# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}


# This is the average number of wrong predictions

loss_func(class = stu3$high_use, prob = stu3$prediction)  



```


